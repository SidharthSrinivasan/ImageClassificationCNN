{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDVDq4R4cQqN"
      },
      "source": [
        "Import and setup some auxiliary functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHPwL1QYcQqU"
      },
      "source": [
        "import torch\n",
        "from torchvision import transforms, datasets\n",
        "import numpy as np\n",
        "import timeit\n",
        "from collections import OrderedDict\n",
        "from pprint import pformat\n",
        "from torch.utils.data.sampler import *\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "from google.colab import drive\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.multiprocessing.set_sharing_strategy('file_system')\n",
        "\n",
        "\n",
        "def run(algorithm, dataset_name, filename):\n",
        "    predicted_test_labels, gt_labels, run_time, parameters_count = algorithm(dataset_name)\n",
        "    if predicted_test_labels is None or gt_labels is None:\n",
        "      return (0, 0, 0)\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for label, prediction in zip(gt_labels, predicted_test_labels):\n",
        "      total += label.size(0)\n",
        "      correct += (prediction.cpu().numpy() == label.cpu().numpy()).sum().item()   # assuming your model runs on GPU\n",
        "      \n",
        "    accuracy = float(correct) / total\n",
        "    \n",
        "    print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
        "    return (correct, accuracy, run_time, parameters_count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17Mjmw05cQq0"
      },
      "source": [
        "def load_data(dataset_name, device, config):\n",
        "    \"\"\"\n",
        "    loads cifar-10 dataset using torchvision, take the last 5k of the training data to be validation data\n",
        "    \"\"\"\n",
        "    CIFAR_training = datasets.CIFAR10(root = './data', train = True, download = True, transform = config['transforms'])\n",
        "    CIFAR_test = datasets.CIFAR10(root = './data', train = False, download = True, transform = config['transforms'])\n",
        "    \n",
        "    training_set = torch.utils.data.Subset(CIFAR_training, list(range(0, 45000)))\n",
        "    validation_set = torch.utils.data.Subset(CIFAR_training, list(range(45000, 50000)))\n",
        "\n",
        "    train_dataloader = torch.utils.data.DataLoader(training_set, batch_size = config['batch_size'], shuffle = True)\n",
        "    valid_dataloader = torch.utils.data.DataLoader(validation_set, batch_size = config['batch_size'], shuffle = True)\n",
        "    test_dataloader = torch.utils.data.DataLoader(CIFAR_test ,batch_size=1, shuffle=True)\n",
        "\n",
        "        \n",
        "    return train_dataloader, valid_dataloader, test_dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2PKEVDSeeJ9"
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 6, kernel_size=5)\n",
        "    nn.init.xavier_uniform_(self.conv1.weight)\n",
        "    self.conv2 = nn.Conv2d(6, 12, kernel_size=5)\n",
        "    self.conv3 = nn.Conv2d(12, 24, kernel_size = 5)\n",
        "    self.fc1 = nn.Linear(384, 64)\n",
        "    self.fc2 = nn.Linear(64, 10)\n",
        "\n",
        "  def forward(self,x):\n",
        "    upsampler = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "    x = upsampler(x)\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "    x = F.relu(self.conv3(x))\n",
        "    x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = F.sigmoid(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    return F.log_softmax(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3GcXjw5emv0"
      },
      "source": [
        "def train(train_dataloader, valid_dataloader, device, config):\n",
        "    model = None\n",
        "    train_losses = []\n",
        "    train_counter = []\n",
        "    validation_losses = []\n",
        "    validation_counter = [i*len(train_dataloader.dataset) for i in range(config['num_epochs'] + 1)]\n",
        "    log_interval = 100\n",
        "\n",
        "\n",
        "    model = Net().to(device)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=config['lr'],\n",
        "                      momentum=0.5, weight_decay=config['weight_decay'])\n",
        "    \n",
        "    for epoch in range(1, config['num_epochs']+1):\n",
        "      for batch_idx, (data, target) in enumerate(train_dataloader):\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "          print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "            epoch, batch_idx * len(data), len(train_dataloader.dataset),\n",
        "            100. * batch_idx / len(train_dataloader), loss.item()))\n",
        "          train_losses.append(loss.item())\n",
        "          train_counter.append(\n",
        "            (batch_idx*64) + ((epoch-1)*len(train_dataloader.dataset)))\n",
        "          \n",
        "      model.eval()\n",
        "      validation_loss = 0\n",
        "      correct = 0\n",
        "      with torch.no_grad():\n",
        "        for data, target in valid_dataloader:\n",
        "          data = data.to(device)\n",
        "          target = target.to(device)\n",
        "          output = model(data)\n",
        "          validation_loss += F.nll_loss(output, target, size_average=False).item()\n",
        "          pred = output.data.max(1, keepdim=True)[1]\n",
        "          correct += pred.eq(target.data.view_as(pred)).sum()\n",
        "      validation_loss /= len(valid_dataloader.dataset)\n",
        "      validation_losses.append(validation_loss)\n",
        "      print('\\nValidation set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "            validation_loss, correct, len(valid_dataloader.dataset),\n",
        "            100. * correct / len(valid_dataloader.dataset)))\n",
        "    return model\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9dIUkH6e5T2"
      },
      "source": [
        "def save_model_colab_for_submission(model):  # if you are running on colab\n",
        "  drive.mount('/content/gdrive/', force_remount=True)\n",
        "  \n",
        "  torch.save(model.to(torch.device(\"cpu\")), '/content/gdrive/My Drive/model.pt') \n",
        "  \n",
        "\n",
        "def save_model_local_for_submission(model):  # if you are running on your local machine\n",
        "  torch.save(model.to(torch.device(\"cpu\")), 'model.pt')\n",
        "  \n",
        "def test(model, test_dataloader, device):\n",
        "  test_predictions = []\n",
        "  true_labels = []\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for data, target in test_dataloader:\n",
        "      data = data.to(device)\n",
        "      target = target.to(device)\n",
        "      output = model(data)\n",
        "      pred = output.data.max(1, keepdim=True)[1]\n",
        "      test_predictions.append(pred.cpu())\n",
        "      true_labels.append(target.data.view_as(pred.cpu()))\n",
        "    \n",
        "  test_predictions = torch.cat(test_predictions, axis = 0)\n",
        "  true_labels = torch.cat(true_labels, axis = 0)\n",
        "\n",
        "  return test_predictions, true_labels\n",
        "\n",
        "def count_parameters(model):\n",
        "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
        "    total_params = 0\n",
        "    for name, parameter in model.named_parameters():\n",
        "        if not parameter.requires_grad: continue\n",
        "        params = parameter.numel()\n",
        "        table.add_row([name, params])\n",
        "        total_params+=params\n",
        "    # uncomment below codes for your debugging\n",
        "    print(table)\n",
        "    print(f\"Total Trainable Params: {total_params}\")\n",
        "    return total_params\n",
        "\n",
        "def run_NN(dataset_name):\n",
        "    # set parameters cifar10\n",
        "  config = {\n",
        "        'lr': 0.01,\n",
        "        'num_epochs': 15,\n",
        "        'batch_size': 20,\n",
        "        'num_classes': 10,\n",
        "        'regular_constant': 0,\n",
        "        'weight_decay': 0.001,\n",
        "        'transforms': transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) }\n",
        "    \n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  \n",
        "  train_dataloader, valid_dataloader, test_dataloader = load_data(dataset_name, device, config)\n",
        "  \n",
        "  model = train(train_dataloader, valid_dataloader, device, config)\n",
        "  parameters_count = count_parameters(model)\n",
        "\n",
        "  device = torch.device(\"cpu\")\n",
        "  start_time = timeit.default_timer()\n",
        "  assert test_dataloader.batch_size == 1, 'Error: You should use use batch size = 1 for the test loader.'\n",
        "  preds, labels = test(model.to(device), test_dataloader, device)\n",
        "  end_time = timeit.default_timer()\n",
        "  \n",
        "\n",
        "  test_time = (end_time - start_time)\n",
        "  print(\"Total run time of testing the model: \", test_time , \" seconds.\")\n",
        "  \n",
        "  save_model_colab_for_submission(model)\n",
        "  \n",
        "  return preds, labels, test_time, parameters_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNNgL7C7cQq-"
      },
      "source": [
        "Main loop. Run time and total score will be shown below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qf9iL8S_cQrB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "55b03579-3238-4163-e608-888860582428"
      },
      "source": [
        "# Don't edit this cell\n",
        "def run_on_dataset(dataset_name, filename):\n",
        "\n",
        "    correct_predict, accuracy, run_time, parameters_count = run(run_NN, dataset_name, filename)\n",
        "\n",
        "    result = OrderedDict(\n",
        "                  correct_predict=correct_predict,\n",
        "                  accuracy=accuracy,\n",
        "                  run_time=run_time,\n",
        "                  parameters_count=parameters_count)\n",
        "    return result\n",
        "\n",
        "\n",
        "def main():\n",
        "    filenames = { \"CIFAR10\": \"predictions_cifar10.txt\"}\n",
        "    result_all = OrderedDict()\n",
        "    for dataset_name in [\"CIFAR10\"]:\n",
        "        result_all = run_on_dataset(dataset_name, filenames[dataset_name])\n",
        "    with open('result.txt', 'w') as f:\n",
        "        f.writelines(pformat(result_all, indent=4))\n",
        "    print(\"\\nResult:\\n\", pformat(result_all, indent=4))\n",
        "\n",
        "\n",
        "main()"
      ],
    }
  ]
}
